{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-29T02:20:48.745497800Z",
     "start_time": "2023-08-29T02:20:46.769374200Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import  nn\n",
    "import torch\n",
    "from torch import optim\n",
    "from mlp import MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### nn.Model 类"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50b240ff2961dfff"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from perception_sequential import Perception\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T02:22:19.910127300Z",
     "start_time": "2023-08-29T02:22:19.899128200Z"
    }
   },
   "id": "6d92d298c1fe9054"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "Perception(\n  (layer): Sequential(\n    (0): Linear(in_features=100, out_features=10000, bias=True)\n    (1): Sigmoid()\n    (2): Linear(in_features=10000, out_features=10, bias=True)\n    (3): Sigmoid()\n  )\n)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Perception(100,10000,10).cuda()\n",
    "model\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T02:27:01.387032200Z",
     "start_time": "2023-08-29T02:27:01.232030500Z"
    }
   },
   "id": "38ecee20ac41a732"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([10])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(100).cuda()\n",
    "output = model(input)\n",
    "output.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T02:27:46.350442800Z",
     "start_time": "2023-08-29T02:27:42.878455200Z"
    }
   },
   "id": "bacbb70f6fad9aa8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 模型处理\n",
    "- 2.4.1 网络模型库： torchvision.models (包含以下经典的网络结构和预训练模型）\n",
    "    - VGG\n",
    "    - ResNet\n",
    "    - Inception 等"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb421416c6b083f4"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "31"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torchvision import models\n",
    "\n",
    "# 通过torchvision.model 直接调用VGG16的网络结构\n",
    "vgg = models.vgg16()\n",
    "# VGG16 的特征层包含13个卷积、13个激活函数ReLu，5个池化，一共31层.注意：这个是特征层\n",
    "len(vgg.features)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T02:35:22.624185200Z",
     "start_time": "2023-08-29T02:35:21.831456400Z"
    }
   },
   "id": "6946393e3d673aaa"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "7"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VGG16d 包含3个全连接、2个ReLU、2个Dropout，一共7层\n",
    "len(vgg.classifier)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T02:45:16.670567300Z",
     "start_time": "2023-08-29T02:45:16.651484500Z"
    }
   },
   "id": "b75b1bc017766a2b"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "Linear(in_features=4096, out_features=1000, bias=True)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可以通过出现的顺序直接索引每一层\n",
    "vgg.classifier[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T02:45:59.610768700Z",
     "start_time": "2023-08-29T02:45:59.602768200Z"
    }
   },
   "id": "48bc3c0c2cec5369"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "Sequential(\n  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (25): ReLU(inplace=True)\n  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (27): ReLU(inplace=True)\n  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (29): ReLU(inplace=True)\n  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 也可以选取某一部分，如下代表了特征网络的最后一个卷积模组\n",
    "vgg.features[24:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T03:05:21.452495Z",
     "start_time": "2023-08-29T03:05:21.423457800Z"
    }
   },
   "id": "f733172b8e92823c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4.2 加载预训练模型\n",
    "- 预训练模型的来因：\n",
    "    - 对于计算机视觉的任务，包括物体检测，我们通常很难拿到很大的数据集，在这种情况下重新训练一个新的模型是比较复杂的，并且不容易调整\n",
    "    - 因此，Fine-tune（微调）是一个常用的选择。所谓Fine-tune是指利用别人在一些数据集上训练好的预训练模型，在自己的数据集上训练自己的模型。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7088750cf68519fb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 具体代码\n",
    "# 第一种： 直接调用别人的预训练模型\n",
    "vgg = models.vgg16(pretrained=True) # 通过torchvision.vgg16 直接叼用VGG16的网络结构\n",
    "\n",
    "# 第二种： 叼用自己的本地预训练模型，或是之前训练过的模型\n",
    "vgg = models.vgg16()\n",
    "state_dict = torch.load(\"Your model path\")\n",
    "# 利用load_state_dict,遍历训练模型的关键字，如果出现在了VGG中，则加载预训练参数\n",
    "# vgg.load_state_dict({k:v for k, v in state_dict_items() if k in vgg.state_dict()})\n",
    "\n",
    "# \n",
    "# 通常来讲，对于不同的检测任务，卷积网络的前两三层的作用是非常类似的，都是提取图像的边缘信息等，因此为了保证模型训练中能够更加稳定，一般会固定预训练网络的前两三个卷积层而不进行参数的学习。例如VGG模型，可以设置前三个卷积模组不进行参数学习，设置方式如下：\n",
    "# 这里对应的10就包含了前面3个卷积层\n",
    "# for layer in range(10):\n",
    "#     for p in vgg[layer].parameters():\n",
    "#         p.requires_grad = False"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "630170b64e463b0a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4.3 模型保存\n",
    "- 代码仅作为说明，不能用于运行\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b84ef021c7a9bb2f"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# torch.save({\n",
    "#     'model' : model.state_dict(),\n",
    "#     'optimizer:' : optimizer.state_dict(),\n",
    "#     'model_path' : \"Your model path\"\n",
    "# })"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T03:11:06.709109400Z",
     "start_time": "2023-08-29T03:11:06.684451800Z"
    }
   },
   "id": "7a705532739fe439"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.5 数据处理\n",
    "- 2.5.1 主流公开数据集\n",
    "    - ImageNet\n",
    "    - PASCAL VOC \n",
    "    - COCO ( Common Objects in Context)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28117cde02cbdb07"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.5.2 数据加载\n",
    "- 三个步骤\n",
    "    - 1)继承Dataset类\n",
    "    - 2)增加数据变换\n",
    "    - 3)继承Dataloader\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c0958c8a2b516da"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "# 不可运行代码\n",
    "# 用法：\n",
    "# 1) 继承Dataset类\n",
    "class my_data(Dataset):\n",
    "    # 初始化读取数据集\n",
    "    def __init__(self,image_path,annotation_path,transform=None):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def __len__(self): #获取数据集的总大小\n",
    "        pass\n",
    "    \n",
    "    def __getitem__(self, id): # 对于指定的id，读取该数据并返回\n",
    "        pass    \n",
    "    \n",
    "# 实例化并开始遍历    \n",
    "dataset = my_data(\"your image path\",\"your annotation path\")\n",
    "for data in dataset:\n",
    "    print(data)\n",
    "        \n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3d5324352ee1d59"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "my_data.__init__() got an unexpected keyword argument 'transforms'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m transforms\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# 将transforms集成到Dataset类中，使用Compose将多个变换整合到一起\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[43mmy_data\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43myour image path\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43myour annotation path\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransforms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\n\u001B[0;32m      5\u001B[0m \u001B[43mtransforms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCompose\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtransforms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mResize\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m256\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# 将图像最短边缩小至256，宽高比例不变\u001B[39;49;00m\n\u001B[0;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# 以0.5的概率随机翻转指定的PIL图像\u001B[39;49;00m\n\u001B[0;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtransforms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mRandomHorizontalFlip\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# 将PIL图像转为Tensor，元素区间从[0, 255]归一到[0, 1]\u001B[39;49;00m\n\u001B[0;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtransforms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mToTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# 进行mean与std为0.5的标准化\u001B[39;49;00m\n\u001B[0;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtransforms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mNormalize\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mTypeError\u001B[0m: my_data.__init__() got an unexpected keyword argument 'transforms'"
     ]
    }
   ],
   "source": [
    "# 2)数据变换和增强 torchvision.transforms. 示意代码，不可运行\n",
    "from torchvision import transforms\n",
    "# 将transforms集成到Dataset类中，使用Compose将多个变换整合到一起\n",
    "dataset = my_data(\"your image path\", \"your annotation path\", transform=transforms.Compose([\n",
    "    transforms.Resize(256), # 将图像最短边缩小至256，宽高比例不变\n",
    "    # 以0.5的概率随机翻转指定的PIL图像\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # 将PIL图像转为Tensor，元素区间从[0, 255]归一到[0, 1]\n",
    "    transforms.ToTensor(),\n",
    "    # 进行mean与std为0.5的标准化\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "]))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T05:18:35.330482200Z",
     "start_time": "2023-08-29T05:18:35.182978300Z"
    }
   },
   "id": "d483b577ef91f00d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 3) 继承dataloader\n",
    "# 前面两部已经可以获取每一个变化后的样本，但是仍然无法进行批量处理，随机选取等操作，因为仍需torch.utils.data.Dataloader类进一步封装\n",
    "# 该类需要4个参数：\n",
    "# 1 继承了Dataset的实例\n",
    "# 2 批量batch的大小\n",
    "# 3 是否打乱参数数据\n",
    "# 4 使用几个线程来加载数据\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "# 使用Dataloader进一步封装Dataset\n",
    "dataloader = DataLoader(dataset,batch_size=4,shuffle=True,num_workers=4) # \n",
    "# 注意：dataloader是一个可迭代对象，对该实例进行迭代即可用于训练过程，其实就是训练实质.\n",
    "data_iter = iter(dataloader)\n",
    "for step in range(iters_per_epoch): # iters_per_epoch 代表每个批次迭代多少次\n",
    "    data = next(data_iter)\n",
    "    \n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1cc4f237844cd580"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GPU 加速\n",
    "- 判断是否可以在GPU上面进行张量运算： torch.cuda.is_available() "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "604bea07d592d21e"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "a = torch.randn(3,3)\n",
    "b = models.vgg16()\n",
    "\n",
    "# Check current cpu is available or not\n",
    "if torch.cuda.is_available():\n",
    "    a = a.cuda()\n",
    "    # 指定将b转移到编号为1的GPU上\n",
    "    #b = b.cuda(1) 这个没有通过\n",
    "    \n",
    "    # 使用torch.device()来指定使用哪一个GPU\n",
    "    device = torch.device(\"cuda:2\") # 这个成功了\n",
    "    device_name =torch.cuda.get_device_name(0)\n",
    "    count = torch.cuda.get_device_capability(0) # 获得GPU最大和最小的CUDA计算能力\n",
    "    print(count)\n",
    "\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T05:45:21.694257100Z",
     "start_time": "2023-08-29T05:45:20.869264700Z"
    }
   },
   "id": "c6faed2ef4d8c641"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 训练可视化工具\n",
    "- TensorBoardX \n",
    "- Visdom 这里只关注Facebook开发的Visdom\n",
    "    - 1) 开启visdom服务- python3 -m visdom.server\n",
    "      2) 打开web，网址：http://localhost:8097"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc78efb4d03ff161"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "data": {
      "text/plain": "'image_random'"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import visdom\n",
    "vis = visdom.Visdom(env='first item')\n",
    "vis.text('first visdom',win='I am here')\n",
    "vis.image(torch.randn(3,256,256),win='image_random')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T06:19:26.241095900Z",
     "start_time": "2023-08-29T06:19:26.084259500Z"
    }
   },
   "id": "61b360fe6197e23f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
