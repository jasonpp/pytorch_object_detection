{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-29T08:32:02.273349100Z",
     "start_time": "2023-08-29T08:32:01.419314200Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import  nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1.1 卷积层\n",
    "- 计算过程\n",
    "    - 书上的是滑动step后每个元素进行相乘\n",
    "    - pytorch中是非常简单的\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "902bc9a852999579"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 快速搭建卷积层\n",
    "conv = nn.Conv2d(in_channels=1,out_channels=1,kernel_size=3,stride=1,padding=1,dilation=1,groups=1,bias=True)  \n",
    "\n",
    "# 查看卷积核的基本信息，本质上是一个Module\n",
    "conv\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T08:36:16.359692900Z",
     "start_time": "2023-08-29T08:36:16.316693100Z"
    }
   },
   "id": "a9269f532efcf024"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "Parameter containing:\ntensor([[[[ 0.0377,  0.2636, -0.2682],\n          [-0.1179,  0.3013,  0.2442],\n          [ 0.3137, -0.0469, -0.1935]]]], requires_grad=True)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过.weight和.bias查看卷积核的权重和偏置\n",
    "conv.weight"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T08:45:13.773765Z",
     "start_time": "2023-08-29T08:45:13.757764400Z"
    }
   },
   "id": "cbaeae5038fb5038"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1.2 激活层函数\n",
    "- 只有卷积层可以吗？\n",
    "    - 答案是不行\n",
    "        - 原因：神经网络如果仅仅是由线性的卷积运算堆叠组成，则其无法形成复杂的表达空间，也就很难提取出高语义的信息，因此还需要加入非线性的映射，又称为激活函数，可以逼近任意的非线性函数，以提升整个神经网络的表达能力。\n",
    "- 在检测任务中常用的激活函数有：\n",
    "    - Sigmoid\n",
    "    - ReLU （为了缓解因为链式求导带来的梯度消失现象，所以才有ReLU，其加强版为：Leaky ReLU函数）\n",
    "    - Softmax （多物体类别常用）\n",
    "        "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8dcc9bef69cab4a5"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[0.7311, 0.7311],\n          [0.7311, 0.7311]]]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "input = torch.ones(1,1,2,2)\n",
    "input\n",
    "sigmod = nn.Sigmoid()\n",
    "sigmod(input)\n",
    "\n",
    "# 其余函数代码比较简单，暂时掠过\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T08:56:30.843535Z",
     "start_time": "2023-08-29T08:56:30.795536Z"
    }
   },
   "id": "fb2d0a8e2dd16707"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1.3 池化层\n",
    "- 目的：降低特征图的参数量，从而提升计算速度，一种降采样操作(优化采样方法)\n",
    "- 常见的池化层：\n",
    "    - 最大值池化（Max Pooling）\n",
    "    - 平均值池化（Average Polling）"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ff359582c044272"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[-1.6962,  1.2758, -0.5516,  0.8100],\n          [-1.3772,  2.0731, -0.8452, -0.8731],\n          [ 0.3330, -1.8309, -0.7143, -2.6112],\n          [ 0.6964,  0.8424,  0.6429,  0.3556]]]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "max_pooling = nn.MaxPool2d(2,stride=2)\n",
    "aver_pooling = nn.AvgPool2d(2,stride=2)\n",
    "input = torch.randn(1,1,4,4)\n",
    "input"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T09:01:47.611907300Z",
     "start_time": "2023-08-29T09:01:47.595907500Z"
    }
   },
   "id": "ca8379239d2f71f1"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[2.0731, 0.8100],\n          [0.8424, 0.6429]]]])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_maxPolling = max_pooling(input)\n",
    "after_maxPolling\n",
    "# after_maxPolling.shape # 看到应用了max_pooling 后的张量形状都发生了改变，平均值也是一样\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T09:04:34.499962500Z",
     "start_time": "2023-08-29T09:04:34.483963Z"
    }
   },
   "id": "e5636a66ef0b0022"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1.4 Dropout层 （一般被广泛应用到全连接层中，一般保留概率设置为0.5）\n",
    "- 出现原因：\n",
    "    - 参数过多然后样本又少，这样下去会产生过拟合\n",
    "- 为什么可以防止过拟合？\n",
    "    - 多模型平均\n",
    "    - 减少神经元依赖\n",
    "    - 生物进化\n",
    "        "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6cf1728e07ef698c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# PyTorch将元素置0来实现Dropout层，第一个参数为置0概率，第二个为是否原地操作\n",
    "dropout = nn.Dropout(0.5,inplace=False)\n",
    "input = torch.randn(2,64,7,7)\n",
    "output = dropout(input)\n",
    "output"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "683f925032164116"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1.5 BN层\n",
    "- 出现原因:\n",
    "    - 浅层参数的微弱变化经过多层线性变换和激活函数后会被放大，会造成深层的网络需要不断的调整以适应这些分布变化，最红导致模型难以训练和收敛\n",
    "- BN层对每一个batch的输入特征进行白化操作：即去均值方差的过程：\n",
    "    - $ 均值\\mu = \\frac{1}{m}  \\sum_{1}^{m}x_{i} $\n",
    "    - $ 方差\\sigma_{B} ^{2}   = \\frac{1}{m}  \\sum_{1}^{m} (x_{i} - \\mu)^{2} $\n",
    "    - $白化 = \\frac{x_{i}-\\mu _{B} }{\\sqrt{\\sigma_{B}^{}2+\\varepsilon  } }  $ "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9a840dfda2b8182"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "295192e33f4472e2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
